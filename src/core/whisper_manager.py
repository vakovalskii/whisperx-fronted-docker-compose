"""
–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏ WhisperX
"""
import os
import threading
import torch
from typing import Optional, Callable

import whisperx

from ..models.schemas import TranscriptionConfig


class WhisperManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏ WhisperX"""
    
    def __init__(self):
        self.model = None
        self.align_model = None
        self.align_metadata = None
        self.diarize_model = None
        self.models_loaded = False
        self.loading_lock = threading.Lock()
        self.device = self._detect_device()
        self.compute_type = self._detect_compute_type()
        print(f"üîß –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}, compute_type: {self.compute_type}")
    
    def _detect_device(self) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞"""
        if torch.cuda.is_available():
            return "cuda"
        else:
            return "cpu"
    
    def _detect_compute_type(self) -> str:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ compute_type"""
        if self.device == "cuda":
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É float16 –Ω–∞ GPU
            try:
                # –ü—Ä–æ–±—É–µ–º —Å–æ–∑–¥–∞—Ç—å —Ç–µ–Ω–∑–æ—Ä float16 –Ω–∞ GPU
                test_tensor = torch.tensor([1.0], dtype=torch.float16, device="cuda")
                return "float16"
            except Exception:
                return "float32"
        else:
            # –î–ª—è CPU –∏—Å–ø–æ–ª—å–∑—É–µ–º int8 –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            return "int8"
    
    def load_models(self, config: TranscriptionConfig, status_callback: Optional[Callable] = None):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π WhisperX –≤ –ø–∞–º—è—Ç—å"""
        with self.loading_lock:
            if self.models_loaded:
                return
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º compute_type
            compute_type = config.compute_type
            if compute_type == "auto":
                compute_type = self.compute_type
                print(f"üîß –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±—Ä–∞–Ω compute_type: {compute_type}")
            
            if status_callback:
                status_callback("loading_whisper_model", "–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper...", 20)
            print(f"üîß –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper: {config.model}")
            self.model = whisperx.load_model(
                config.model, 
                self.device, 
                compute_type=compute_type
            )
            
            if status_callback:
                status_callback("loading_align_model", "–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è...", 25)
            print("üîß –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è...")
            
            # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
            try:
                self.align_model, self.align_metadata = whisperx.load_align_model(
                    language_code=config.language, 
                    device=self.device
                )
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –¥–ª—è —è–∑—ã–∫–∞ '{config.language}': {e}")
                print("üîß –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è...")
                try:
                    # –ü–æ–ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ –∫–∞–∫ fallback
                    self.align_model, self.align_metadata = whisperx.load_align_model(
                        language_code="en", 
                        device=self.device
                    )
                    print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∞—è –º–æ–¥–µ–ª—å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –∫–∞–∫ fallback")
                except Exception as e2:
                    print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è: {e2}")
                    print("‚ö†Ô∏è –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –±–µ–∑ —Ç–æ—á–Ω–æ–≥–æ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫")
                    self.align_model = None
                    self.align_metadata = None
            
            if config.diarize and config.hf_token:
                if status_callback:
                    status_callback("loading_diarize_model", "–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏...", 28)
                print("üîß –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏...")
                print(f"üîë HF Token –¥–ª—è –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏: {config.hf_token[:20]}...{config.hf_token[-10:] if len(config.hf_token) > 30 else config.hf_token}")
                print(f"üîë –î–ª–∏–Ω–∞ —Ç–æ–∫–µ–Ω–∞: {len(config.hf_token)} —Å–∏–º–≤–æ–ª–æ–≤")
                print(f"üîë –¢–æ–∫–µ–Ω –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 'hf_': {config.hf_token.startswith('hf_')}")
                self.diarize_model = whisperx.diarize.DiarizationPipeline(
                    use_auth_token=config.hf_token, 
                    device=self.device
                )
            
            self.models_loaded = True
            print("‚úÖ –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
    
    def transcribe_audio(self, audio_path: str, config: TranscriptionConfig, status_callback: Optional[Callable] = None) -> dict:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ
        
        Args:
            audio_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
            status_callback: Callback –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        """
        if not self.models_loaded:
            self.load_models(config, status_callback)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
        if status_callback:
            status_callback("loading_audio", "–ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞...", 32)
        print(f"üéµ –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞: {audio_path}")
        audio = whisperx.load_audio(audio_path)
        
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è
        if status_callback:
            status_callback("transcribing", "–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏...", 45)
        print("üéØ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏...")
        result = self.model.transcribe(audio, batch_size=config.batch_size)
        
        # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ
        if self.align_model and self.align_metadata:
            if status_callback:
                status_callback("aligning", "–í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞...", 65)
            print("üìê –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞...")
            result = whisperx.align(
                result["segments"], 
                self.align_model, 
                self.align_metadata, 
                audio, 
                self.device
            )
        
        # –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
        if config.diarize and self.diarize_model:
            if status_callback:
                status_callback("diarizing", "–î–∏–∞—Ä–∏–∑–∞—Ü–∏—è —Å–ø–∏–∫–µ—Ä–æ–≤...", 72)
            print("üë• –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è —Å–ø–∏–∫–µ—Ä–æ–≤...")
            diarize_segments = self.diarize_model(audio)
            result = whisperx.assign_word_speakers(diarize_segments, result)
        
        return result
    
    async def transcribe_audio_chunk(self, audio_data, sample_rate: int = 16000, language: str = "ru") -> str:
        """
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ —á–∞–Ω–∫–∞ –¥–ª—è real-time —Ä–µ–∂–∏–º–∞
        
        Args:
            audio_data: Numpy array —Å –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–º–∏
            sample_rate: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
            language: –Ø–∑—ã–∫ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
            
        Returns:
            str: –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        """
        if not self.models_loaded:
            # –î–ª—è real-time –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑–æ–≤—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            from ..models.schemas import TranscriptionConfig
            basic_config = TranscriptionConfig(
                model="base",
                language=language,
                compute_type="auto",
                batch_size=16,
                diarize=False,
                hf_token=""
            )
            self.load_models(basic_config)
        
        try:
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ audio_data - —ç—Ç–æ numpy array float32
            import numpy as np
            if not isinstance(audio_data, np.ndarray):
                audio_data = np.array(audio_data, dtype=np.float32)
            elif audio_data.dtype != np.float32:
                audio_data = audio_data.astype(np.float32)
            
            # WhisperX –æ–∂–∏–¥–∞–µ—Ç –∞—É–¥–∏–æ —Å —á–∞—Å—Ç–æ—Ç–æ–π 16kHz, –Ω—É–∂–Ω–æ —Ä–µ—Å–µ–º–ø–ª–∏—Ä–æ–≤–∞—Ç—å –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if sample_rate != 16000:
                # –ü—Ä–æ—Å—Ç–æ–µ —Ä–µ—Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (–≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å librosa)
                import scipy.signal
                target_length = int(len(audio_data) * 16000 / sample_rate)
                audio_data = scipy.signal.resample(audio_data, target_length)
            
            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ —á–∞–Ω–∫
            result = self.model.transcribe(audio_data, batch_size=1)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if result and "segments" in result and result["segments"]:
                text_parts = []
                for segment in result["segments"]:
                    if "text" in segment:
                        text_parts.append(segment["text"].strip())
                
                return " ".join(text_parts).strip()
            
            return ""
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —á–∞–Ω–∫–∞: {e}")
            return ""
    
    @property
    def is_loaded(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –ª–∏ –º–æ–¥–µ–ª–∏"""
        return self.models_loaded 